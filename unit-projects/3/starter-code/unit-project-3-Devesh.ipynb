{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SF-DAT-21 | Unit Project 3\n",
    "\n",
    "In this project, you will perform a logistic regression on the admissions data we've been working with in Unit Projects 1 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import pylab as pl\n",
    "from sklearn import linear_model\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   admit    gre   gpa  prestige\n",
      "0      0  380.0  3.61       3.0\n",
      "1      1  660.0  3.67       3.0\n",
      "2      1  800.0  4.00       1.0\n",
      "3      1  640.0  3.19       4.0\n",
      "4      0  520.0  2.93       4.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>760.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>560.0</td>\n",
       "      <td>2.98</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>3.08</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>540.0</td>\n",
       "      <td>3.39</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>3.92</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>3.22</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>760.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>3.08</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>700.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>3.44</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>780.0</td>\n",
       "      <td>3.87</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>2.56</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>3.75</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>540.0</td>\n",
       "      <td>3.81</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>3.17</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3.63</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>2.82</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>680.0</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>760.0</td>\n",
       "      <td>3.35</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>800.0</td>\n",
       "      <td>3.66</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>620.0</td>\n",
       "      <td>3.61</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>520.0</td>\n",
       "      <td>3.74</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>780.0</td>\n",
       "      <td>3.22</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>3.29</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>1</td>\n",
       "      <td>540.0</td>\n",
       "      <td>3.77</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>1</td>\n",
       "      <td>680.0</td>\n",
       "      <td>3.76</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>1</td>\n",
       "      <td>680.0</td>\n",
       "      <td>2.42</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>1</td>\n",
       "      <td>620.0</td>\n",
       "      <td>3.37</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>3.78</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>3.49</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>3.63</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>1</td>\n",
       "      <td>800.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3.12</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>2.70</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>3.65</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>1</td>\n",
       "      <td>540.0</td>\n",
       "      <td>3.49</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>3.51</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>1</td>\n",
       "      <td>480.0</td>\n",
       "      <td>2.62</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>3.02</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>1</td>\n",
       "      <td>740.0</td>\n",
       "      <td>3.86</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>3.36</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3.17</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3.51</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>1</td>\n",
       "      <td>800.0</td>\n",
       "      <td>3.05</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>1</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3.88</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>1</td>\n",
       "      <td>600.0</td>\n",
       "      <td>3.38</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>1</td>\n",
       "      <td>620.0</td>\n",
       "      <td>3.75</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>1</td>\n",
       "      <td>460.0</td>\n",
       "      <td>3.99</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>3.04</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0</td>\n",
       "      <td>460.0</td>\n",
       "      <td>2.63</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>3.65</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>397 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     admit    gre   gpa  prestige\n",
       "0        0  380.0  3.61       3.0\n",
       "1        1  660.0  3.67       3.0\n",
       "2        1  800.0  4.00       1.0\n",
       "3        1  640.0  3.19       4.0\n",
       "4        0  520.0  2.93       4.0\n",
       "5        1  760.0  3.00       2.0\n",
       "6        1  560.0  2.98       1.0\n",
       "7        0  400.0  3.08       2.0\n",
       "8        1  540.0  3.39       3.0\n",
       "9        0  700.0  3.92       2.0\n",
       "10       0  800.0  4.00       4.0\n",
       "11       0  440.0  3.22       1.0\n",
       "12       1  760.0  4.00       1.0\n",
       "13       0  700.0  3.08       2.0\n",
       "14       1  700.0  4.00       1.0\n",
       "15       0  480.0  3.44       3.0\n",
       "16       0  780.0  3.87       4.0\n",
       "17       0  360.0  2.56       3.0\n",
       "18       0  800.0  3.75       2.0\n",
       "19       1  540.0  3.81       1.0\n",
       "20       0  500.0  3.17       3.0\n",
       "21       1  660.0  3.63       2.0\n",
       "22       0  600.0  2.82       4.0\n",
       "23       0  680.0  3.19       4.0\n",
       "24       1  760.0  3.35       2.0\n",
       "25       1  800.0  3.66       1.0\n",
       "26       1  620.0  3.61       1.0\n",
       "27       1  520.0  3.74       4.0\n",
       "28       1  780.0  3.22       2.0\n",
       "29       0  520.0  3.29       1.0\n",
       "..     ...    ...   ...       ...\n",
       "370      1  540.0  3.77       2.0\n",
       "371      1  680.0  3.76       3.0\n",
       "372      1  680.0  2.42       1.0\n",
       "373      1  620.0  3.37       1.0\n",
       "374      0  560.0  3.78       2.0\n",
       "375      0  560.0  3.49       4.0\n",
       "376      0  620.0  3.63       2.0\n",
       "377      1  800.0  4.00       2.0\n",
       "378      0  640.0  3.12       3.0\n",
       "379      0  540.0  2.70       2.0\n",
       "380      0  700.0  3.65       2.0\n",
       "381      1  540.0  3.49       2.0\n",
       "382      0  540.0  3.51       2.0\n",
       "383      0  660.0  4.00       1.0\n",
       "384      1  480.0  2.62       2.0\n",
       "385      0  420.0  3.02       1.0\n",
       "386      1  740.0  3.86       2.0\n",
       "387      0  580.0  3.36       2.0\n",
       "388      0  640.0  3.17       2.0\n",
       "389      0  640.0  3.51       2.0\n",
       "390      1  800.0  3.05       2.0\n",
       "391      1  660.0  3.88       2.0\n",
       "392      1  600.0  3.38       3.0\n",
       "393      1  620.0  3.75       2.0\n",
       "394      1  460.0  3.99       3.0\n",
       "395      0  620.0  4.00       2.0\n",
       "396      0  560.0  3.04       3.0\n",
       "397      0  460.0  2.63       2.0\n",
       "398      0  700.0  3.65       2.0\n",
       "399      0  600.0  3.89       3.0\n",
       "\n",
       "[397 rows x 4 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw = pd.read_csv(\"../../dataset/admissions.csv\")\n",
    "df = df_raw.dropna()\n",
    "print df.head()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Frequency Tables\n",
    "\n",
    "#### Question 1. Let's create a frequency table of our variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# frequency table for prestige and whether or not someone was admitted\n",
    "#a=pd.Series(df.admit,df.prestige)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11e368250>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEACAYAAABCl1qQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npXJYmJlZKoeFmZmlcliYmVmq/w8f0nzHLDhmWAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11e359590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[['prestige','admit']].plot(kind='Hist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A histogram can be constructed for a frequency distribution. It reveals the following:\n",
    "1)There are around 275 students who did not get admission\n",
    "2)A total of 125 students were admitted\n",
    "In terms of Prestige, we can infer the following:\n",
    "1)Around 150 students who applied came from a Prestige 2 institute\n",
    "2)~125 who applied were for a Prestige 3 institute\n",
    "3)75 people came from prestige 4 institute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11e489d50>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEACAYAAACznAEdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11e450c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[(df.admit==1)][['prestige']].plot(kind='Hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "admit       126\n",
       "gre         126\n",
       "gpa         126\n",
       "prestige    126\n",
       "dtype: int64"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.admit==1)].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following can be inferred about the students who were admitted:\n",
    "1)~35 students with prestige =1\n",
    "2)~55 students with prestige =2\n",
    "3)~25 students with prestige =3\n",
    "4)~10 students with prestige =4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Return of dummy variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2.1. Create class or dummy variables for prestige."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prestige_1</th>\n",
       "      <th>prestige_2</th>\n",
       "      <th>prestige_3</th>\n",
       "      <th>prestige_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>397 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     prestige_1  prestige_2  prestige_3  prestige_4\n",
       "0           0.0         0.0         1.0         0.0\n",
       "1           0.0         0.0         1.0         0.0\n",
       "2           1.0         0.0         0.0         0.0\n",
       "3           0.0         0.0         0.0         1.0\n",
       "4           0.0         0.0         0.0         1.0\n",
       "5           0.0         1.0         0.0         0.0\n",
       "6           1.0         0.0         0.0         0.0\n",
       "7           0.0         1.0         0.0         0.0\n",
       "8           0.0         0.0         1.0         0.0\n",
       "9           0.0         1.0         0.0         0.0\n",
       "10          0.0         0.0         0.0         1.0\n",
       "11          1.0         0.0         0.0         0.0\n",
       "12          1.0         0.0         0.0         0.0\n",
       "13          0.0         1.0         0.0         0.0\n",
       "14          1.0         0.0         0.0         0.0\n",
       "15          0.0         0.0         1.0         0.0\n",
       "16          0.0         0.0         0.0         1.0\n",
       "17          0.0         0.0         1.0         0.0\n",
       "18          0.0         1.0         0.0         0.0\n",
       "19          1.0         0.0         0.0         0.0\n",
       "20          0.0         0.0         1.0         0.0\n",
       "21          0.0         1.0         0.0         0.0\n",
       "22          0.0         0.0         0.0         1.0\n",
       "23          0.0         0.0         0.0         1.0\n",
       "24          0.0         1.0         0.0         0.0\n",
       "25          1.0         0.0         0.0         0.0\n",
       "26          1.0         0.0         0.0         0.0\n",
       "27          0.0         0.0         0.0         1.0\n",
       "28          0.0         1.0         0.0         0.0\n",
       "29          1.0         0.0         0.0         0.0\n",
       "..          ...         ...         ...         ...\n",
       "370         0.0         1.0         0.0         0.0\n",
       "371         0.0         0.0         1.0         0.0\n",
       "372         1.0         0.0         0.0         0.0\n",
       "373         1.0         0.0         0.0         0.0\n",
       "374         0.0         1.0         0.0         0.0\n",
       "375         0.0         0.0         0.0         1.0\n",
       "376         0.0         1.0         0.0         0.0\n",
       "377         0.0         1.0         0.0         0.0\n",
       "378         0.0         0.0         1.0         0.0\n",
       "379         0.0         1.0         0.0         0.0\n",
       "380         0.0         1.0         0.0         0.0\n",
       "381         0.0         1.0         0.0         0.0\n",
       "382         0.0         1.0         0.0         0.0\n",
       "383         1.0         0.0         0.0         0.0\n",
       "384         0.0         1.0         0.0         0.0\n",
       "385         1.0         0.0         0.0         0.0\n",
       "386         0.0         1.0         0.0         0.0\n",
       "387         0.0         1.0         0.0         0.0\n",
       "388         0.0         1.0         0.0         0.0\n",
       "389         0.0         1.0         0.0         0.0\n",
       "390         0.0         1.0         0.0         0.0\n",
       "391         0.0         1.0         0.0         0.0\n",
       "392         0.0         0.0         1.0         0.0\n",
       "393         0.0         1.0         0.0         0.0\n",
       "394         0.0         0.0         1.0         0.0\n",
       "395         0.0         1.0         0.0         0.0\n",
       "396         0.0         0.0         1.0         0.0\n",
       "397         0.0         1.0         0.0         0.0\n",
       "398         0.0         1.0         0.0         0.0\n",
       "399         0.0         0.0         1.0         0.0\n",
       "\n",
       "[397 rows x 4 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_ranks = pd.get_dummies(df.prestige,prefix='prestige')\n",
    "dummy_ranks.columns = ['prestige_1', 'prestige_2', 'prestige_3', 'prestige_4']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2.2. When modeling our class variables, how many do we need?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:If we are creating a Dummy varibale for a categorical variable that has n values , we would need a total of 'n' new featues variables "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3. Hand calculating odds ratios\n",
    "\n",
    "Develop your intuition about expected outcomes by hand calculating odds ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   admit    gre   gpa  prestige_1  prestige_2  prestige_3  prestige_4\n",
      "0      0  380.0  3.61         0.0         0.0         1.0         0.0\n",
      "1      1  660.0  3.67         0.0         0.0         1.0         0.0\n",
      "2      1  800.0  4.00         1.0         0.0         0.0         0.0\n",
      "3      1  640.0  3.19         0.0         0.0         0.0         1.0\n",
      "4      0  520.0  2.93         0.0         0.0         0.0         1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_to_keep = ['admit', 'gre', 'gpa']\n",
    "handCalc = df[cols_to_keep].join(dummy_ranks.ix[:, 'prestige_1':])\n",
    "print handCalc.head()\n",
    "type(handCalc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11e714890>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEACAYAAACznAEdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11e4f0090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# crosstab prestige 1 admission\n",
    "# frequency table cutting prestige and whether or not someone was admitted\n",
    "df[(df.admit==1)][['prestige']].plot(kind='Hist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3.1. Use the cross tab above to calculate the odds of being admitted to grad school if you attended a #1 ranked college."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "admit       28\n",
       "gre         28\n",
       "gpa         28\n",
       "prestige    28\n",
       "dtype: int64"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Assumption- Prestige 1 maps to rank1\n",
    "df[(df.admit==0) & (df.prestige==1)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "admit       33\n",
       "gre         33\n",
       "gpa         33\n",
       "prestige    33\n",
       "dtype: int64"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.admit==1) & (df.prestige==1)].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total student who were admitted with Rank#1= 33\n",
    "Total student who were not admitted with Rank#1= 28\n",
    "odds ratio= 1.17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3.2. Now calculate the odds of admission if you did not attend a #1 ranked college."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "admit       93\n",
       "gre         93\n",
       "gpa         93\n",
       "prestige    93\n",
       "dtype: int64"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.admit==1) & (df.prestige!=1)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "admit       93\n",
       "gre         93\n",
       "gpa         93\n",
       "prestige    93\n",
       "dtype: int64"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.admit==1) & (df.prestige!=1)].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total student who were admitted and who did not attend a rank 1 college= 93\n",
    "Total student who were not admitted and who did not attend a rank 1 college= 243\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3.3. Calculate the odds ratio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "odds ratio=(admitted with rank !=1)/(admitted with rank =1)\n",
    "odds=243/93=2.61"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3.4. Write this finding in a sentenance:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:Students who came from a a college with Rank!=1 have twice as much chance of getting admitted compared to those who apply from college with rank=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3.5. Print the cross tab for prestige_4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "admit       12\n",
       "gre         12\n",
       "gpa         12\n",
       "prestige    12\n",
       "dtype: int64"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.admit==1) & (df.prestige==4)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "admit       114\n",
       "gre         114\n",
       "gpa         114\n",
       "prestige    114\n",
       "dtype: int64"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.admit==1) & (df.prestige!=4)].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3.6. Calculate the OR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "odds ratio= Students admitted with prestige 4/students who were admitted with Prestige!=4\n",
    "odds ratio=12/114=.105"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3.7. Write this finding in a sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:students who apply from a prestige 4 college have only 1 in 105 chance in getting admission "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4. Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   admit    gre   gpa  prestige_2  prestige_3  prestige_4\n",
      "0      0  380.0  3.61         0.0         1.0         0.0\n",
      "1      1  660.0  3.67         0.0         1.0         0.0\n",
      "2      1  800.0  4.00         0.0         0.0         0.0\n",
      "3      1  640.0  3.19         0.0         0.0         1.0\n",
      "4      0  520.0  2.93         0.0         0.0         1.0\n"
     ]
    }
   ],
   "source": [
    "# create a clean data frame for the regression\n",
    "cols_to_keep = ['admit', 'gre', 'gpa']\n",
    "data = df[cols_to_keep].join(dummy_ranks.ix[:, 'prestige_2':])\n",
    "print data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to add a constant term for our Logistic Regression.  The statsmodels function we're going to be using requires that intercepts/constants are specified explicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# manually add the intercept\n",
    "data['intercept'] = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4.1. Set the covariates to a variable called train_cols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.head()\n",
    "train_cols = data[['gre','gpa','prestige_2','prestige_3','prestige_4']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4.2. Fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = linear_model.LogisticRegression()\n",
    "model.fit(train_cols,data.admit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70528967254408059"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(train_cols,data.admit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model = sm.Logit(df.admit,train_cols).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4.3. Print the summary results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.81701706])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00178497,  0.23229458, -0.60347467, -1.17214957, -1.37729795]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4.4. Calculate the odds ratios of the coeffincients and their 95% CI intervals\n",
    "\n",
    "hint 1: np.exp(X)\n",
    "\n",
    "hint 2: conf['OR'] = params\n",
    "\n",
    "        conf.columns = ['2.5%', '97.5%', 'OR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The odds for GRE 1.0017865640072277--> \n",
      "The odds for GPA 1.2614912842017518-->\n",
      "The odds for PRES2 0.54690800592502209--\n",
      "The odds for PRES3 0.30970050233473029--\n",
      "The odds for PRES4 0.25225925011363726--\n"
     ]
    }
   ],
   "source": [
    "odds_gre = np.exp(0.00178497)\n",
    "print  \"The odds for GRE %r--> \" %odds_gre\n",
    "\n",
    "odds_gpa = np.exp(0.23229458)\n",
    "print \"The odds for GPA %r-->\" %odds_gpa\n",
    "\n",
    "odds_pres_2 = np.exp(-0.60347467)\n",
    "print \"The odds for PRES2 %r--\" %odds_pres_2\n",
    "\n",
    "odds_pres_3 = np.exp(-1.17214957)\n",
    "print \"The odds for PRES3 %r--\" %odds_pres_3\n",
    "\n",
    "odds_pres_4 = np.exp(-1.37729795)\n",
    "print \"The odds for PRES4 %r--\" %odds_pres_4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.00178657,  1.26149128,  0.546908  ,  0.3097005 ,  0.25225925])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(model.coef_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4.5. Interpret the OR of Prestige_2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:The coeff. for prestige_2 is .547, which means that for logit increase for a unit increase in prestige _2 is .5468 i.e. the log_it increase in admission goes up by .5468 as one goes from a college of Prestige_2 to Prestige_3.\n",
    "\n",
    "This corresponds to an increase in probability = exp(.5468)=72% as one moves from a college of reputation 1 to 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7277154730073663"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(.5468)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4.6. Interpret the OR of GPA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:The coeff for GPA = 1.26, which indicates that logit increase in admission corrsponding to a unit increase in GPA is 1.26. This corresponds to an increase in the chances of getting admitted by exp(1.26)~52%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5254214873653824"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(1.26)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Predicted probablities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a way of evaluating our classifier, we're going to recreate the dataset with every logical combination of input values.  This will allow us to see how the predicted probability of admission increases/decreases across different variables.  First we're going to generate the combinations using a helper function called cartesian (above).\n",
    "\n",
    "We're going to use np.linspace to create a range of values for \"gre\" and \"gpa\".  This creates a range of linearly spaced values from a specified min and maximum value--in our case just the min/max observed values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cartesian(arrays, out=None):\n",
    "    \"\"\"\n",
    "    Generate a cartesian product of input arrays.\n",
    "    Parameters\n",
    "    ----------\n",
    "    arrays : list of array-like\n",
    "        1-D arrays to form the cartesian product of.\n",
    "    out : ndarray\n",
    "        Array to place the cartesian product in.\n",
    "    Returns\n",
    "    -------\n",
    "    out : ndarray\n",
    "        2-D array of shape (M, len(arrays)) containing cartesian products\n",
    "        formed of input arrays.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> cartesian(([1, 2, 3], [4, 5], [6, 7]))\n",
    "    array([[1, 4, 6],\n",
    "           [1, 4, 7],\n",
    "           [1, 5, 6],\n",
    "           [1, 5, 7],\n",
    "           [2, 4, 6],\n",
    "           [2, 4, 7],\n",
    "           [2, 5, 6],\n",
    "           [2, 5, 7],\n",
    "           [3, 4, 6],\n",
    "           [3, 4, 7],\n",
    "           [3, 5, 6],\n",
    "           [3, 5, 7]])\n",
    "    \"\"\"\n",
    "\n",
    "    arrays = [np.asarray(x) for x in arrays]\n",
    "    dtype = arrays[0].dtype\n",
    "\n",
    "    n = np.prod([x.size for x in arrays])\n",
    "    if out is None:\n",
    "        out = np.zeros([n, len(arrays)], dtype=dtype)\n",
    "\n",
    "    m = n / arrays[0].size\n",
    "    out[:,0] = np.repeat(arrays[0], m)\n",
    "    if arrays[1:]:\n",
    "        cartesian(arrays[1:], out=out[0:m,1:])\n",
    "        for j in xrange(1, arrays[0].size):\n",
    "            out[j*m:(j+1)*m,1:] = out[0:m,1:]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 220.          284.44444444  348.88888889  413.33333333  477.77777778\n",
      "  542.22222222  606.66666667  671.11111111  735.55555556  800.        ]\n",
      "[ 2.26        2.45333333  2.64666667  2.84        3.03333333  3.22666667\n",
      "  3.42        3.61333333  3.80666667  4.        ]\n"
     ]
    }
   ],
   "source": [
    "# instead of generating all possible values of GRE and GPA, we're going\n",
    "# to use an evenly spaced range of 10 values from the min to the max\n",
    "gres = np.linspace(data['gre'].min(), data['gre'].max(), 10)\n",
    "\n",
    "print gres\n",
    "# array([ 220.        ,  284.44444444,  348.88888889,  413.33333333,\n",
    "#         477.77777778,  542.22222222,  606.66666667,  671.11111111,\n",
    "#         735.55555556,  800.        ])\n",
    "\n",
    "gpas = np.linspace(data['gpa'].min(), data['gpa'].max(), 10)\n",
    "\n",
    "print gpas\n",
    "# array([ 2.26      ,  2.45333333,  2.64666667,  2.84      ,  3.03333333,\n",
    "#         3.22666667,  3.42      ,  3.61333333,  3.80666667,  4.        ])\n",
    "\n",
    "# enumerate all possibilities\n",
    "combos = pd.DataFrame(cartesian([gres, gpas, [1, 2, 3, 4], [1.]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5.1. Recreate the dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# recreate the dummy variables\n",
    "\n",
    "# keep only what we need for making predictions\n",
    "dummy_ranks = pd.get_dummies(df.prestige,prefix='prestige')\n",
    "dummy_ranks.columns = ['prestige_1', 'prestige_2', 'prestige_3', 'prestige_4']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5.2. Make predictions on the enumerated dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.589121\n",
      "         Iterations 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>admit</td>      <th>  No. Observations:  </th>  <td>   397</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   392</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     4</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Mon, 06 Jun 2016</td> <th>  Pseudo R-squ.:     </th>  <td>0.05722</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>10:07:33</td>     <th>  Log-Likelihood:    </th> <td> -233.88</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -248.08</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>1.039e-05</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gre</th>        <td>    0.0014</td> <td>    0.001</td> <td>    1.308</td> <td> 0.191</td> <td>   -0.001     0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gpa</th>        <td>   -0.1323</td> <td>    0.195</td> <td>   -0.680</td> <td> 0.497</td> <td>   -0.514     0.249</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prestige_2</th> <td>   -0.9562</td> <td>    0.302</td> <td>   -3.171</td> <td> 0.002</td> <td>   -1.547    -0.365</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prestige_3</th> <td>   -1.5375</td> <td>    0.332</td> <td>   -4.627</td> <td> 0.000</td> <td>   -2.189    -0.886</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prestige_4</th> <td>   -1.8699</td> <td>    0.401</td> <td>   -4.658</td> <td> 0.000</td> <td>   -2.657    -1.083</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                  admit   No. Observations:                  397\n",
       "Model:                          Logit   Df Residuals:                      392\n",
       "Method:                           MLE   Df Model:                            4\n",
       "Date:                Mon, 06 Jun 2016   Pseudo R-squ.:                 0.05722\n",
       "Time:                        10:07:33   Log-Likelihood:                -233.88\n",
       "converged:                       True   LL-Null:                       -248.08\n",
       "                                        LLR p-value:                 1.039e-05\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
       "------------------------------------------------------------------------------\n",
       "gre            0.0014      0.001      1.308      0.191        -0.001     0.003\n",
       "gpa           -0.1323      0.195     -0.680      0.497        -0.514     0.249\n",
       "prestige_2    -0.9562      0.302     -3.171      0.002        -1.547    -0.365\n",
       "prestige_3    -1.5375      0.332     -4.627      0.000        -2.189    -0.886\n",
       "prestige_4    -1.8699      0.401     -4.658      0.000        -2.657    -1.083\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_stats= sm.Logit(df.admit,train_cols).fit()\n",
    "model_stats.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5.3. Interpret findings for the last 4 observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "\n",
    "Plot the probability of being admitted into graduate school, stratified by GPA and GRE score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
